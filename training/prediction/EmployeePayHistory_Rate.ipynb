{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# EmployeePayHistory",
   "id": "6f1fc649a55f5a01"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import the necessary libraries",
   "id": "813e00a3c19c06a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from common_functions import drop_sk_datetime_added_columns as drop_columns, train_model, get_engine, \\\n",
    "    read_data_return_df, plot_predictions, plot_feature_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "import torch"
   ],
   "id": "2f34b7feaa8173c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Connecting to the database\n",
    "Connecting to the UnitedOutdoors sql server database and reading the data from the EmployeePayHistory table"
   ],
   "id": "a5f14d7f9e467259"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "engine = get_engine()",
   "id": "b3e7b8fc429dd931",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading in the data",
   "id": "2331b3f65bfb7034"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sql_query_employeepayhistory = \"SELECT * FROM EmployeePayHistory\"\n",
    "employeepayhistory_df = read_data_return_df(sql_query_employeepayhistory, engine)\n",
    "\n",
    "employeepayhistory_df.head()"
   ],
   "id": "2f33602f0ee437f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sql_query_businessentity = \"SELECT * FROM BusinessEntity\"\n",
    "businessentity_df = read_data_return_df(sql_query_businessentity, engine)\n",
    "\n",
    "businessentity_df.head()"
   ],
   "id": "1df7f9e44139c8df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sql_query_employee = \"SELECT EMPLOYEE_EMPLOYEE_EmployeeID, EMPLOYEE_EMPLOYEE_ManagerID, EMPLOYEE_EMPLOYEE_DeptID, EMPLOYEE_EMPLOYEE_State, EMPLOYEE_EMPLOYEE_Start_Date, EMPLOYEE_EMPLOYEE_OrganizationLevel, EMPLOYEE_EMPLOYEE_BirthDate, EMPLOYEE_EMPLOYEE_SickLeaveHours FROM Employee\"\n",
    "employee_df = read_data_return_df(sql_query_employee, engine)\n",
    "\n",
    "employee_df.head()"
   ],
   "id": "934977591a8e7cb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Cleaning",
   "id": "a0d896693d2845d2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# combining the dataframes\n",
    "combined_df = pd.merge(employeepayhistory_df ,businessentity_df, left_on='EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_BusinessEntityID', right_on='BUSINESSENTITY_sk', suffixes=('_eph', '_b'))\n",
    "\n",
    "combined_df = pd.merge(combined_df, employee_df, left_on='BUSINESSENTITY_BUSINESSENTITY_BusinessEntityID', right_on='EMPLOYEE_EMPLOYEE_EmployeeID', suffixes=('', '_e'), how='outer')"
   ],
   "id": "3f9227374bac967f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dropping unnecessary columns\n",
    "columns_to_keep = ['EMPLOYEE_EMPLOYEE_EmployeeID', 'EMPLOYEE_EMPLOYEE_ManagerID', 'EMPLOYEE_EMPLOYEE_DeptID', 'EMPLOYEE_EMPLOYEE_State', 'EMPLOYEE_EMPLOYEE_BirthDate', 'EMPLOYEE_EMPLOYEE_Start_Date', 'EMPLOYEE_EMPLOYEE_OrganizationLevel', 'EMPLOYEE_EMPLOYEE_SickLeaveHours', 'EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_Rate', 'EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_PayFrequency', 'BUSINESSENTITY_CONTACTTYPE_ContactTypeID', 'EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_RateChangeDate']\n",
    "\n",
    "combined_df = combined_df[columns_to_keep]"
   ],
   "id": "63172beb01aa08d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# converting EMPLOYEE_EMPLOYEE_State\n",
    "combined_df['EMPLOYEE_EMPLOYEE_State'] = combined_df['EMPLOYEE_EMPLOYEE_State'].astype('category').cat.codes\n",
    "\n",
    "# Convert the datetime column to number of days since Unix epoch\n",
    "combined_df['EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_RateChangeDate'] = pd.to_datetime(combined_df['EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_RateChangeDate'], errors='coerce')\n",
    "combined_df['EMPLOYEE_EMPLOYEE_BirthDate'] = pd.to_datetime(combined_df['EMPLOYEE_EMPLOYEE_BirthDate'], errors='coerce')\n",
    "combined_df['EMPLOYEE_EMPLOYEE_Start_Date'] = pd.to_datetime(combined_df['EMPLOYEE_EMPLOYEE_Start_Date'], errors='coerce')\n",
    "\n",
    "# Convert the datetime objects to number of days since Unix epoch\n",
    "combined_df['EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_RateChangeDate'] = (combined_df['EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_RateChangeDate'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1D')\n",
    "combined_df['EMPLOYEE_EMPLOYEE_BirthDate'] = (combined_df['EMPLOYEE_EMPLOYEE_BirthDate'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1D')\n",
    "combined_df['EMPLOYEE_EMPLOYEE_Start_Date'] = (combined_df['EMPLOYEE_EMPLOYEE_Start_Date'] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1D')"
   ],
   "id": "83192be0900f321d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fixing null values\n",
    "drop_columns(combined_df)\n",
    "\n",
    "# dropping all rows where EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_Rate is null/-1\n",
    "combined_df = combined_df[combined_df['EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_Rate'] != -1]"
   ],
   "id": "c66720678c0e9f2c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_df.info()",
   "id": "69d18275401798c4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Data Analysis\n",
    "Predicting the rate of pay for employees based on the other columns, using a variety of models"
   ],
   "id": "7d81394f7b7c3678"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the data",
   "id": "ba10fcf97abaaebe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# splitting the data\n",
    "X = combined_df.drop(columns=['EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_Rate'])\n",
    "y = combined_df['EMPLOYEEPAYHISTORY_EMPLOYEEPAYHISTORY_Rate']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "ea8c1a360b185bb8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Regression",
   "id": "95577bca331bd731"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "dbf647bcf4b0c7d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "9ec66c53d1acef2f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "lr_y_pred = lr_model.predict(X_test_scaled)"
   ],
   "id": "49360809b260da6f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "78850cb6747964d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "lr_mse = mean_squared_error(y_test, lr_y_pred)\n",
    "lr_r2 = r2_score(y_test, lr_y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {lr_mse}')\n",
    "print(f'R2 Score: {lr_r2}')"
   ],
   "id": "2e9c49cf51571196",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualizing the results\n",
    "plot_predictions(y_test, lr_y_pred, 'Linear Regression')"
   ],
   "id": "d28416503081474c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "lr_results = pd.DataFrame({'Actual': y_test, 'Predicted': lr_y_pred})\n",
    "lr_results['Difference'] = lr_results['Actual'] - lr_results['Predicted']\n",
    "lr_results['Absolute Difference'] = np.abs(lr_results['Difference'])\n",
    "lr_results['Squared Difference'] = lr_results['Difference'] ** 2\n",
    "\n",
    "lr_results"
   ],
   "id": "4b8ac2b41e8692f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, lr_model.coef_)"
   ],
   "id": "aef5934bdc0b0afe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decision Tree Regressor",
   "id": "75993f177543ac17"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "dtr_model = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "dtr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "c7cbf3be8f86b8d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "dtr_y_pred = dtr_model.predict(X_test_scaled)"
   ],
   "id": "55a6e4bbafdfa162",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "2dd6395e37862cb4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "dtr_mse = mean_squared_error(y_test, dtr_y_pred)\n",
    "dtr_r2 = r2_score(y_test, dtr_y_pred)\n",
    "print(f'Mean Squared Error: {dtr_mse}')\n",
    "print(f'R2 Score: {dtr_r2}')"
   ],
   "id": "7200fe609f3fa1fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualizing the decision tree\n",
    "plt.figure(figsize=(50, 50))\n",
    "plot_tree(dtr_model, filled=True, feature_names=X.columns)\n",
    "plt.show()"
   ],
   "id": "a3694b3867a7cc44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "dtr_results = pd.DataFrame({'Actual': y_test, 'Predicted': dtr_y_pred})\n",
    "dtr_results['Difference'] = dtr_results['Actual'] - dtr_results['Predicted']\n",
    "dtr_results['Absolute Difference'] = np.abs(dtr_results['Difference'])\n",
    "dtr_results['Squared Difference'] = dtr_results['Difference'] ** 2\n",
    "\n",
    "dtr_results"
   ],
   "id": "415ce494aeaea294",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, dtr_model.feature_importances_)"
   ],
   "id": "82e6bffc3be4665d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "2224dc6fc069289a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "rf_model.fit(X_train_scaled, y_train)"
   ],
   "id": "383b2e2a918ac20a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "rf_y_pred = rf_model.predict(X_test_scaled)"
   ],
   "id": "37a88c5868c79d7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "b8c7a3a2395eb7e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "rf_mse = mean_squared_error(y_test, rf_y_pred)\n",
    "rf_r2 = r2_score(y_test, rf_y_pred)\n",
    "print(f'Mean Squared Error: {rf_mse}')\n",
    "print(f'R2 Score: {rf_r2}')"
   ],
   "id": "5e4903cecae28508",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the results\n",
    "plot_predictions(y_test, rf_y_pred, 'Random Forest')"
   ],
   "id": "97eafd8e35b727ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "rf_results = pd.DataFrame({'Actual': y_test, 'Predicted': rf_y_pred})\n",
    "rf_results['Difference'] = rf_results['Actual'] - rf_results['Predicted']\n",
    "rf_results['Absolute Difference'] = np.abs(rf_results['Difference'])\n",
    "rf_results['Squared Difference'] = rf_results['Difference'] ** 2\n",
    "\n",
    "rf_results"
   ],
   "id": "2fbcf069692540f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the predictions\n",
    "plot_feature_importance(X.columns, rf_model.feature_importances_)"
   ],
   "id": "820784f22722625e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradient Boosting",
   "id": "8e90b3540e74488"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100)\n",
    "\n",
    "gb_model.fit(X_train_scaled, y_train)"
   ],
   "id": "1119aa50b8fec2cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "gb_y_pred = gb_model.predict(X_test_scaled)"
   ],
   "id": "ca3dbb1c4b1506a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "e98336270c1037c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "gb_mse = mean_squared_error(y_test, gb_y_pred)\n",
    "gb_r2 = r2_score(y_test, gb_y_pred)\n",
    "print(f'Mean Squared Error: {gb_mse}')\n",
    "print(f'R2 Score: {gb_r2}')"
   ],
   "id": "d31705b14da5eb55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the results\n",
    "plot_predictions(y_test, gb_y_pred, 'Gradient Boosting')"
   ],
   "id": "64cb2ad166d91bf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "gb_results = pd.DataFrame({'Actual': y_test, 'Predicted': gb_y_pred})\n",
    "gb_results['Difference'] = gb_results['Actual'] - gb_results['Predicted']\n",
    "gb_results['Absolute Difference'] = np.abs(gb_results['Difference'])\n",
    "gb_results['Squared Difference'] = gb_results['Difference'] ** 2\n",
    "\n",
    "gb_results"
   ],
   "id": "729047fba6478992",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the predictions\n",
    "plot_feature_importance(X.columns, gb_model.feature_importances_)"
   ],
   "id": "8b349435442c02ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pytorch Neural Network",
   "id": "a1b410aa80d27ea4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check if the GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# converting the scaled data to tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)  # target variable often doesn't need scaling\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)"
   ],
   "id": "d0e755c040ed0b94",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# instantiate the model\n",
    "p_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_train_tensor.shape[1], 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1)\n",
    ").to(device)\n",
    "\n",
    "# define the loss function and the optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(p_model.parameters(), lr=0.01)\n",
    "\n",
    "# Create TensorDatasets for training and test data\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders for training and test data\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Train the model\n",
    "train_model(p_model, criterion, optimizer, train_loader, num_epochs=1000)"
   ],
   "id": "96d8fba18b6c22aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "b9e6b8763a3aaf25"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "p_model.eval()\n",
    "p_mse_list = []\n",
    "p_r2_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = p_model(inputs)\n",
    "        mse = mean_squared_error(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy())\n",
    "        p_mse_list.append(mse)\n",
    "        \n",
    "        # Only calculate R^2 score if there are more than one samples\n",
    "        if len(targets) > 1:\n",
    "            r2 = r2_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy())\n",
    "            p_r2_list.append(r2)\n",
    "\n",
    "# Calculate the average metrics\n",
    "p_avg_mse = np.mean(p_mse_list)\n",
    "p_avg_r2 = np.mean(p_r2_list) if p_r2_list else None\n",
    "\n",
    "print(f'Average Mean Squared Error: {p_avg_mse}')\n",
    "print(f'Average R2 Score: {p_avg_r2}')"
   ],
   "id": "292681151b44a53c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "p_results = pd.DataFrame({'Actual': y_test_tensor.cpu().detach().numpy(), 'Predicted': p_model(X_test_tensor).cpu().detach().numpy().flatten()})\n",
    "p_results['Difference'] = p_results['Actual'] - p_results['Predicted']\n",
    "p_results['Absolute Difference'] = np.abs(p_results['Difference'])\n",
    "p_results['Squared Difference'] = p_results['Difference'] ** 2\n",
    "\n",
    "p_results"
   ],
   "id": "5ccb728b21692bab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature results\n",
    "plot_predictions(y_test_tensor.cpu().detach().numpy(), p_model(X_test_tensor).cpu().detach().numpy().flatten(), 'Pytorch Network')"
   ],
   "id": "b22412abbe84f43e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
