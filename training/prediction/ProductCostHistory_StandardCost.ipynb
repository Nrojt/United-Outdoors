{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# ProductCostHistory\n",
    "Predicting StandardCost"
   ],
   "id": "2eee1822fbbb157e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing Libraries",
   "id": "8fadf5e9b13cf066"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from common_functions import drop_sk_datetime_added_columns as drop_columns, train_model, get_engine, \\\n",
    "    read_data_return_df, plot_predictions, plot_feature_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "import torch"
   ],
   "id": "374fdd5bef447ba3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Connecting to the database",
   "id": "f211fc7fc063cf0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "engine = get_engine()",
   "id": "c1a17cd8a6d54654",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading the data",
   "id": "2f93cf7250e8fba7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "productcosthistory_sql_query = \"SELECT * FROM ProductCostHistory\"\n",
    "productcosthistory_df = read_data_return_df(productcosthistory_sql_query, engine)\n",
    "\n",
    "productcosthistory_df.head()"
   ],
   "id": "47db1a0decefabf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "product_sql_query = \"SELECT * FROM Product\"\n",
    "product_df = read_data_return_df(product_sql_query, engine)\n",
    "\n",
    "product_df.head()"
   ],
   "id": "5c869194c3c75b28",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data Cleaning",
   "id": "e55b255984388c56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# combining the two dataframes\n",
    "combined_df = pd.merge(productcosthistory_df, product_df, left_on='PRODUCTCOSTHISTORY_PRODUCTCOSTHISTORY_ProductID', right_on='PRODUCT_sk')\n",
    "\n",
    "# dropping the datetime_added and sk columns. Also handling the null values\n",
    "drop_columns(combined_df)"
   ],
   "id": "279edc3844fb27e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns_to_drop = ['PRODUCTCOSTHISTORY_PRODUCTCOSTHISTORY_ProductID', 'PRODUCT_UNITMEASURE_SIZE_ID', 'PRODUCT_UNITMEASURE_WEIGHT_ID', 'PRODUCT_PRODUCTPRODUCTPHOTO_PhotoID', 'PRODUCT_PMPDC_DescriptionID', 'PRODUCT_PRODUCT_Name', 'PRODUCT_PRODUCT_Number', 'PRODUCT_PRODUCT_MakeFlag', 'PRODUCT_PRODUCT_FinishedGoodsFlag', 'PRODUCT_PRODUCT_Color', 'PRODUCT_PRODUCTSUBCATEGORY_SubCategory', 'PRODUCT_PRODUCTCATEGORY_Category', 'PRODUCT_PRODUCTMODEL_Name', 'PRODUCT_PRODUCTMODEL_CatalogDescription', 'PRODUCT_PRODUCTMODEL_Instructions', 'PRODUCT_ILLUSTRATION_Diagram', 'PRODUCT_CULTURE_Name', 'PRODUCT_PRODUCTDESCRIPTION_Desc', 'PRODUCT_PRODUCTPRODUCTPHOTO_Primary', 'PRODUCT_PRODUCTPHOTO_ThumbnailPhoto', 'PRODUCT_PRODUCTPHOTO_ThumbnailPhotoHexString', 'PRODUCT_PRODUCTPHOTO_ThumbnailPhotoFileName', 'PRODUCT_PRODUCTPHOTO_LargePhoto', 'PRODUCT_PRODUCTPHOTO_LargePhotoHexString', 'PRODUCT_PRODUCTPHOTO_LargePhotoFileName', 'PRODUCT_PRODUCT_SellStartDate', 'PRODUCT_PRODUCT_SellEndDate',  'PRODUCT_PRODUCT_StandardCost', 'PRODUCT_PRODUCTMODELILLUSTRATION_IllustrationID', 'PRODUCT_PRODUCT_SafetyStockLevel', 'PRODUCT_PRODUCT_ReorderPoint', 'PRODUCT_PRODUCT_ListPrice']\n",
    "\n",
    "combined_df.drop(columns=columns_to_drop, inplace=True)"
   ],
   "id": "4a357bb3aca050fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "combined_df['PRODUCTCOSTHISTORY_PRODUCTCOSTHISTORY_StartDate'] = combined_df['PRODUCTCOSTHISTORY_PRODUCTCOSTHISTORY_StartDate'].astype(str).str.replace('-', '').astype(int)\n",
    "combined_df['PRODUCTCOSTHISTORY_PRODUCTCOSTHISTORY_EndDate'] = combined_df['PRODUCTCOSTHISTORY_PRODUCTCOSTHISTORY_EndDate'].astype(str).str.replace('-', '').astype(int)\n",
    "\n",
    "combined_df['PRODUCT_PRODUCT_SubCategoryID'] = combined_df['PRODUCT_PRODUCT_SubCategoryID'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PMPDC_CultureID'] = combined_df['PRODUCT_PMPDC_CultureID'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PRODUCT_ProductLine'] = combined_df['PRODUCT_PRODUCT_ProductLine'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PRODUCT_Size'] = combined_df['PRODUCT_PRODUCT_Size'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PRODUCT_Class'] = combined_df['PRODUCT_PRODUCT_Class'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PRODUCT_Style'] = combined_df['PRODUCT_PRODUCT_Style'].astype('category').cat.codes"
   ],
   "id": "49af885b40566dff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_df.head()",
   "id": "99ebef7277bfe398",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data preprocessing",
   "id": "fe5ab3c1b7359d86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the data",
   "id": "91e313dcc379b38d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# splitting the data\n",
    "X = combined_df.drop(columns=['PRODUCTCOSTHISTORY_PRODUCTCOSTHISTORY_StandardCost'])\n",
    "y = combined_df['PRODUCTCOSTHISTORY_PRODUCTCOSTHISTORY_StandardCost']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "9c74615f348b226",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "3419422864c8c2a5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Regression",
   "id": "83906fd5d71c140d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "b97797aad93b2f45",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "f2e840d616745458",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "lr_y_pred = lr_model.predict(X_test_scaled)"
   ],
   "id": "a69295776c3adc03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the data",
   "id": "d770bb0ebe55ba92"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "lr_mse = mean_squared_error(y_test, lr_y_pred)\n",
    "lr_r2 = r2_score(y_test, lr_y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {lr_mse}')\n",
    "print(f'R2 Score: {lr_r2}')"
   ],
   "id": "e70a9dae41815947",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualizing the results\n",
    "plot_predictions(y_test, lr_y_pred, 'Linear Regression')"
   ],
   "id": "6cb9ad87dd208272",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "lr_results = pd.DataFrame({'Actual': y_test, 'Predicted': lr_y_pred})\n",
    "lr_results['Difference'] = lr_results['Actual'] - lr_results['Predicted']\n",
    "lr_results['Absolute Difference'] = np.abs(lr_results['Difference'])\n",
    "lr_results['Squared Difference'] = lr_results['Difference'] ** 2\n",
    "\n",
    "lr_results"
   ],
   "id": "e349b6badc56a366",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, lr_model.coef_)"
   ],
   "id": "c392f53dc5ac2e85",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decision Tree",
   "id": "3086ff0ce5df080a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "dtr_model = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "dtr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "c895a3f2dda5a42a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "dtr_y_pred = dtr_model.predict(X_test_scaled)"
   ],
   "id": "42490d1b3d8279ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the data",
   "id": "5865de202a4111ea"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "dtr_mse = mean_squared_error(y_test, dtr_y_pred)\n",
    "dtr_r2 = r2_score(y_test, dtr_y_pred)\n",
    "print(f'Mean Squared Error: {dtr_mse}')\n",
    "print(f'R2 Score: {dtr_r2}')"
   ],
   "id": "65be1f9e46e7d7b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualizing the decision tree\n",
    "plt.figure(figsize=(50, 50))\n",
    "plot_tree(dtr_model, filled=True, feature_names=X.columns)\n",
    "plt.show()"
   ],
   "id": "c7ac62b8639f9582",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "dtr_results = pd.DataFrame({'Actual': y_test, 'Predicted': dtr_y_pred})\n",
    "dtr_results['Difference'] = dtr_results['Actual'] - dtr_results['Predicted']\n",
    "dtr_results['Absolute Difference'] = np.abs(dtr_results['Difference'])\n",
    "dtr_results['Squared Difference'] = dtr_results['Difference'] ** 2\n",
    "\n",
    "dtr_results"
   ],
   "id": "99bf15e2e8704348",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, dtr_model.feature_importances_)"
   ],
   "id": "3a18d532bd7e6b95",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "33b2d92eb122bde1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "rfr_model = RandomForestRegressor(n_estimators=200)\n",
    "\n",
    "rfr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "329f7dfb1de2d976",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "rfr_y_pred = rfr_model.predict(X_test_scaled)"
   ],
   "id": "f37cc117b6e2a7d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the data",
   "id": "b19ffd079d598670"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "rfr_mse = mean_squared_error(y_test, rfr_y_pred)\n",
    "rfr_r2 = r2_score(y_test, rfr_y_pred)\n",
    "print(f'Mean Squared Error: {rfr_mse}')\n",
    "print(f'R2 Score: {rfr_r2}')"
   ],
   "id": "f073bf1e3f7ef91",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the results\n",
    "plot_predictions(y_test, rfr_y_pred, 'Random Forest')"
   ],
   "id": "d0af312a928dc46a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "rfr_results = pd.DataFrame({'Actual': y_test, 'Predicted': rfr_y_pred})\n",
    "rfr_results['Difference'] = rfr_results['Actual'] - rfr_results['Predicted']\n",
    "rfr_results['Absolute Difference'] = np.abs(rfr_results['Difference'])\n",
    "rfr_results['Squared Difference'] = rfr_results['Difference'] ** 2\n",
    "\n",
    "rfr_results"
   ],
   "id": "a1ba480ed9df409f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, rfr_model.feature_importances_)"
   ],
   "id": "7f5c2899d90f98f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradient Boosting",
   "id": "866cd30dceca2b27"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "gbr_model = GradientBoostingRegressor(n_estimators=200)\n",
    "\n",
    "gbr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "e2eb2eb01736a1d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "gbr_y_pred = gbr_model.predict(X_test_scaled)"
   ],
   "id": "97cd94d29100b25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the data",
   "id": "6cdf4715afe67a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "gbr_mse = mean_squared_error(y_test, gbr_y_pred)\n",
    "gbr_r2 = r2_score(y_test, gbr_y_pred)\n",
    "print(f'Mean Squared Error: {gbr_mse}')\n",
    "print(f'R2 Score: {gbr_r2}')"
   ],
   "id": "6990121d7f241d5f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the results\n",
    "plot_predictions(y_test, gbr_y_pred, 'Gradient Boosting')"
   ],
   "id": "65c0fe8dd7dd389b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "gbr_results = pd.DataFrame({'Actual': y_test, 'Predicted': gbr_y_pred})\n",
    "gbr_results['Difference'] = gbr_results['Actual'] - gbr_results['Predicted']\n",
    "gbr_results['Absolute Difference'] = np.abs(gbr_results['Difference'])\n",
    "gbr_results['Squared Difference'] = gbr_results['Difference'] ** 2\n",
    "\n",
    "gbr_results"
   ],
   "id": "32c291f920d19f23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, gbr_model.feature_importances_)"
   ],
   "id": "3917376d7308df61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Neural Network",
   "id": "5a2ca3b207415543"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check if the GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# converting the scaled data to tensors\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)  # target variable often doesn't need scaling\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)"
   ],
   "id": "a6d7ffa81435247c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# instantiate the model\n",
    "p_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_train_tensor.shape[1], 64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1)\n",
    ").to(device)\n",
    "\n",
    "# define the loss function and the optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(p_model.parameters(), lr=0.01)\n",
    "\n",
    "# Create TensorDatasets for training and test data\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders for training and test data\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Train the model\n",
    "train_model(p_model, criterion, optimizer, train_loader, num_epochs=1000)"
   ],
   "id": "53c61711260aa20a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the data",
   "id": "70d75a6507e2bc00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "p_model.eval()\n",
    "p_mse_list = []\n",
    "p_r2_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = p_model(inputs)\n",
    "        mse = mean_squared_error(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy())\n",
    "        r2 = r2_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy())\n",
    "        p_mse_list.append(mse)\n",
    "        p_r2_list.append(r2)\n",
    "\n",
    "# Calculate the average metrics\n",
    "p_avg_mse = np.mean(p_mse_list)\n",
    "p_avg_r2 = np.mean(p_r2_list)\n",
    "\n",
    "print(f'Average Mean Squared Error: {p_avg_mse}')\n",
    "print(f'Average R2 Score: {p_avg_r2}')"
   ],
   "id": "ba2524c1cad3375c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "p_results = pd.DataFrame({'Actual': y_test_tensor.cpu().detach().numpy(), 'Predicted': p_model(X_test_tensor).cpu().detach().numpy().flatten()})\n",
    "p_results['Difference'] = p_results['Actual'] - p_results['Predicted']\n",
    "p_results['Absolute Difference'] = np.abs(p_results['Difference'])\n",
    "p_results['Squared Difference'] = p_results['Difference'] ** 2\n",
    "\n",
    "p_results"
   ],
   "id": "2c4926cb2f3c9f55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# printing the average absolute difference\n",
    "print(f'Average Absolute Difference: {p_results[\"Absolute Difference\"].mean()}')"
   ],
   "id": "7ab140a6eca816ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the results\n",
    "plot_predictions(y_test_tensor.cpu().detach().numpy(), p_model(X_test_tensor).cpu().detach().numpy().flatten(), 'Pytorch Network')"
   ],
   "id": "cddb7f882a423690",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
