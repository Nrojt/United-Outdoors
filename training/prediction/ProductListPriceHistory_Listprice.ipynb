{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# ProductListPriceHistory",
   "id": "490d383803b60b88"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import the required libraries",
   "id": "1936dd6ebce6ff90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from common_functions import drop_sk_datetime_added_columns as drop_columns, train_model, get_engine, \\\n",
    "    read_data_return_df, plot_predictions, plot_feature_importance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import plot_tree\n",
    "import torch"
   ],
   "id": "8c166702c37f25d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Connecting to the database",
   "id": "dd2205b16c400bbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "engine = get_engine()",
   "id": "cfb95601011cc341",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Reading the data",
   "id": "a928d55de3412892"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sql_query = \"SELECT * FROM ProductListPriceHistory\"\n",
    "productlistpricehistory_df = read_data_return_df(sql_query, engine)\n",
    "\n",
    "productlistpricehistory_df.head()"
   ],
   "id": "bce1d68f3dfc5b93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sql_query = \"SELECT * FROM Product\"\n",
    "product_df = read_data_return_df(sql_query, engine)\n",
    "\n",
    "product_df.head()"
   ],
   "id": "8d5343cf5aef71e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data cleaning",
   "id": "43da075fbb6da516"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# combining the two dataframes\n",
    "combined_df = pd.merge(productlistpricehistory_df, product_df, left_on='PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_ProductID', right_on='PRODUCT_sk')\n",
    "\n",
    "# dropping the columns\n",
    "drop_columns(combined_df)"
   ],
   "id": "ea21beae863f6cc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# drop the unnecessary columns\n",
    "columns_to_drop = ['PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_ProductID', 'PRODUCT_UNITMEASURE_SIZE_ID', 'PRODUCT_UNITMEASURE_WEIGHT_ID', 'PRODUCT_PRODUCTPRODUCTPHOTO_PhotoID', 'PRODUCT_PMPDC_DescriptionID', 'PRODUCT_PRODUCT_Name', 'PRODUCT_PRODUCT_Number', 'PRODUCT_PRODUCT_MakeFlag', 'PRODUCT_PRODUCT_FinishedGoodsFlag', 'PRODUCT_PRODUCT_Color', 'PRODUCT_PRODUCTSUBCATEGORY_SubCategory', 'PRODUCT_PRODUCTCATEGORY_Category', 'PRODUCT_PRODUCTMODEL_Name', 'PRODUCT_PRODUCTMODEL_CatalogDescription', 'PRODUCT_PRODUCTMODEL_Instructions', 'PRODUCT_ILLUSTRATION_Diagram', 'PRODUCT_CULTURE_Name', 'PRODUCT_PRODUCTDESCRIPTION_Desc', 'PRODUCT_PRODUCTPRODUCTPHOTO_Primary', 'PRODUCT_PRODUCTPHOTO_ThumbnailPhoto', 'PRODUCT_PRODUCTPHOTO_ThumbnailPhotoHexString', 'PRODUCT_PRODUCTPHOTO_ThumbnailPhotoFileName', 'PRODUCT_PRODUCTPHOTO_LargePhoto', 'PRODUCT_PRODUCTPHOTO_LargePhotoHexString', 'PRODUCT_PRODUCTPHOTO_LargePhotoFileName', 'PRODUCT_PRODUCT_SellStartDate', 'PRODUCT_PRODUCT_SellEndDate', 'PRODUCT_PRODUCT_ListPrice', 'PRODUCT_PRODUCT_StandardCost']\n",
    "\n",
    "combined_df.drop(columns=columns_to_drop, inplace=True)"
   ],
   "id": "873b044dbc7e165d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# converting the dates to integers (2013-05-30 to 20130530)\n",
    "combined_df.fillna(-1, inplace=True)\n",
    "combined_df['PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_StartDate'] = combined_df['PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_StartDate'].astype(str).str.replace('-', '').astype(int)\n",
    "combined_df['PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_EndDate'] = combined_df['PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_EndDate'].astype(str).str.replace('-', '').astype(int)\n",
    "\n",
    "combined_df['PRODUCT_PRODUCT_SubCategoryID'] = combined_df['PRODUCT_PRODUCT_SubCategoryID'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PMPDC_CultureID'] = combined_df['PRODUCT_PMPDC_CultureID'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PRODUCT_ProductLine'] = combined_df['PRODUCT_PRODUCT_ProductLine'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PRODUCT_Size'] = combined_df['PRODUCT_PRODUCT_Size'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PRODUCT_Class'] = combined_df['PRODUCT_PRODUCT_Class'].astype('category').cat.codes\n",
    "combined_df['PRODUCT_PRODUCT_Style'] = combined_df['PRODUCT_PRODUCT_Style'].astype('category').cat.codes"
   ],
   "id": "908d6377684fbbe0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dropping all rows where PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_ListPrice is null/-1\n",
    "combined_df = combined_df[combined_df['PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_ListPrice'] != -1]"
   ],
   "id": "be4da73d87e63030",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "combined_df.head()",
   "id": "bd64402de52ba789",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data preprocessing",
   "id": "203e1a8300b2936d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Splitting the data",
   "id": "6bc49355c1e9000a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# splitting the data\n",
    "X = combined_df.drop(columns=['PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_ListPrice'])\n",
    "y = combined_df['PRODUCTLISTPRICEHISTORY_PRODUCTLISTPRICEHISTORY_ListPrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ],
   "id": "21831b39cbf060e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training",
   "id": "63ef83fe6c219912"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Linear Regression",
   "id": "9ef4896fa5c598e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# scaling the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ],
   "id": "e30c6e7676479ee7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "lr_model = LinearRegression()\n",
    "\n",
    "lr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "906c1c3c850c7542",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "lr_y_pred = lr_model.predict(X_test_scaled)"
   ],
   "id": "8ab0c0fe47e05381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "43d6b997c6d7ea8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "lr_mse = mean_squared_error(y_test, lr_y_pred)\n",
    "lr_r2 = r2_score(y_test, lr_y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {lr_mse}')\n",
    "print(f'R2 Score: {lr_r2}')"
   ],
   "id": "8a0255c9e28ca223",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualizing the results\n",
    "plot_predictions(y_test, lr_y_pred, 'Linear Regression')"
   ],
   "id": "1483618fa8f217b0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "lr_results = pd.DataFrame({'Actual': y_test, 'Predicted': lr_y_pred})\n",
    "lr_results['Difference'] = lr_results['Actual'] - lr_results['Predicted']\n",
    "lr_results['Absolute Difference'] = np.abs(lr_results['Difference'])\n",
    "lr_results['Squared Difference'] = lr_results['Difference'] ** 2\n",
    "\n",
    "lr_results"
   ],
   "id": "e9a624183374a7c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, lr_model.coef_)"
   ],
   "id": "792698575f3e7af6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Decision Tree",
   "id": "7c992ceda65ea044"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "dtr_model = DecisionTreeRegressor(max_depth=5)\n",
    "\n",
    "dtr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "512416419a3cacbb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "dtr_y_pred = dtr_model.predict(X_test_scaled)"
   ],
   "id": "4a870d9cd203d5d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "b4a703c0f2be580e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "dtr_mse = mean_squared_error(y_test, dtr_y_pred)\n",
    "dtr_r2 = r2_score(y_test, dtr_y_pred)\n",
    "print(f'Mean Squared Error: {dtr_mse}')\n",
    "print(f'R2 Score: {dtr_r2}')"
   ],
   "id": "d0e51cabb73f2a2b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualizing the decision tree\n",
    "plt.figure(figsize=(50, 50))\n",
    "plot_tree(dtr_model, filled=True, feature_names=X.columns)\n",
    "plt.show()"
   ],
   "id": "efef0fe04b192e80",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "dtr_results = pd.DataFrame({'Actual': y_test, 'Predicted': dtr_y_pred})\n",
    "dtr_results['Difference'] = dtr_results['Actual'] - dtr_results['Predicted']\n",
    "dtr_results['Absolute Difference'] = np.abs(dtr_results['Difference'])\n",
    "dtr_results['Squared Difference'] = dtr_results['Difference'] ** 2\n",
    "\n",
    "dtr_results"
   ],
   "id": "7668ad0883cdad4b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, dtr_model.feature_importances_)"
   ],
   "id": "9499fc72c5977613",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Random Forest",
   "id": "35e9ec8f1cab57b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "rfr_model = RandomForestRegressor(n_estimators=100)\n",
    "\n",
    "rfr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "6655a042e892210d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "rfr_y_pred = rfr_model.predict(X_test_scaled)"
   ],
   "id": "3c891a5bdc042154",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "e790e2f97629653"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "rfr_mse = mean_squared_error(y_test, rfr_y_pred)\n",
    "rfr_r2 = r2_score(y_test, rfr_y_pred)\n",
    "print(f'Mean Squared Error: {rfr_mse}')\n",
    "print(f'R2 Score: {rfr_r2}')"
   ],
   "id": "af1a65486b503a3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the results\n",
    "plot_predictions(y_test, rfr_y_pred, 'Random Forest')"
   ],
   "id": "d8a2ef4db3ba8e3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "rfr_results = pd.DataFrame({'Actual': y_test, 'Predicted': rfr_y_pred})\n",
    "rfr_results['Difference'] = rfr_results['Actual'] - rfr_results['Predicted']\n",
    "rfr_results['Absolute Difference'] = np.abs(rfr_results['Difference'])\n",
    "rfr_results['Squared Difference'] = rfr_results['Difference'] ** 2\n",
    "\n",
    "rfr_results"
   ],
   "id": "f1782878398a7f9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, rfr_model.feature_importances_)"
   ],
   "id": "da5375cdb60a2d0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Gradient Boosting",
   "id": "a9e772f9c4ef8cb9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# fitting the model\n",
    "gbr_model = GradientBoostingRegressor(n_estimators=100)\n",
    "\n",
    "gbr_model.fit(X_train_scaled, y_train)"
   ],
   "id": "5aea07f2b7ff1fca",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# predicting the values\n",
    "gbr_y_pred = gbr_model.predict(X_test_scaled)"
   ],
   "id": "441e01da2fb2c0b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "5b207b8d0954f8ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# calculating the metrics\n",
    "gbr_mse = mean_squared_error(y_test, gbr_y_pred)\n",
    "gbr_r2 = r2_score(y_test, gbr_y_pred)\n",
    "print(f'Mean Squared Error: {gbr_mse}')\n",
    "print(f'R2 Score: {gbr_r2}')"
   ],
   "id": "e025ed55cf8a4179",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the results\n",
    "plot_predictions(y_test, gbr_y_pred, 'Gradient Boosting')"
   ],
   "id": "32774163f8dccd1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "gbr_results = pd.DataFrame({'Actual': y_test, 'Predicted': gbr_y_pred})\n",
    "gbr_results['Difference'] = gbr_results['Actual'] - gbr_results['Predicted']\n",
    "gbr_results['Absolute Difference'] = np.abs(gbr_results['Difference'])\n",
    "gbr_results['Squared Difference'] = gbr_results['Difference'] ** 2\n",
    "\n",
    "gbr_results"
   ],
   "id": "3f56ef8b65c3500c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the feature importances, which means how much each column contributes to the prediction\n",
    "plot_feature_importance(X.columns, gbr_model.feature_importances_)"
   ],
   "id": "1a6b10a2f67aa185",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Pytorch Network",
   "id": "6672661c8c631ba9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check if the GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# converting the data to tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32).to(device)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).to(device)"
   ],
   "id": "3c123e687e45b04e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# instantiate the model\n",
    "p_model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(X_train_tensor.shape[1], 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(32, 1)\n",
    ").to(device)\n",
    "\n",
    "# define the loss function and the optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(p_model.parameters(), lr=0.01)\n",
    "\n",
    "# Create TensorDatasets for training and test data\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders for training and test data\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32)\n",
    "\n",
    "# Train the model\n",
    "train_model(p_model, criterion, optimizer, train_loader, num_epochs=1000)"
   ],
   "id": "d9ee2fc27d0e9664",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Calculating the metrics and visualizing the results",
   "id": "3c906457c34ef680"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate the model\n",
    "p_model.eval()\n",
    "p_mse_list = []\n",
    "p_r2_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = p_model(inputs)\n",
    "        mse = mean_squared_error(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy())\n",
    "        r2 = r2_score(targets.cpu().detach().numpy(), outputs.cpu().detach().numpy())\n",
    "        p_mse_list.append(mse)\n",
    "        p_r2_list.append(r2)\n",
    "\n",
    "# Calculate the average metrics\n",
    "p_avg_mse = np.mean(p_mse_list)\n",
    "p_avg_r2 = np.mean(p_r2_list)\n",
    "\n",
    "print(f'Average Mean Squared Error: {p_avg_mse}')\n",
    "print(f'Average R2 Score: {p_avg_r2}')"
   ],
   "id": "de23fec6fae5538b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# dataframe with the predictions and the actual values, plus other metrics\n",
    "p_results = pd.DataFrame({'Actual': y_test_tensor.cpu().detach().numpy(), 'Predicted': p_model(X_test_tensor).cpu().detach().numpy().flatten()})\n",
    "p_results['Difference'] = p_results['Actual'] - p_results['Predicted']\n",
    "p_results['Absolute Difference'] = np.abs(p_results['Difference'])\n",
    "p_results['Squared Difference'] = p_results['Difference'] ** 2\n",
    "\n",
    "p_results"
   ],
   "id": "161345cc0191ca31",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# printing the average absolute difference\n",
    "print(f'Average Absolute Difference: {p_results[\"Absolute Difference\"].mean()}')"
   ],
   "id": "6d96577be6a4374"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plotting the results\n",
    "plot_predictions(y_test_tensor.cpu().detach().numpy(), p_model(X_test_tensor).cpu().detach().numpy().flatten(), 'Pytorch Network')"
   ],
   "id": "f14b266b94378ec4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
